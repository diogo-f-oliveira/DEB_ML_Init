{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93f9e1c9-4fce-417b-a378-446dab13030b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import ipywidgets as widgets\n",
    "import pickle\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5874082-d253-47ca-9b6b-9c99a5fc76d9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the 'project' directory to the path\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "from project_code.data.load_data import load_dataframes\n",
    "from project_code.data.prepare_data_sklearn import get_features_targets\n",
    "from project_code.data.prepare_data_pytorch import prepare_data_tensors\n",
    "from project_code.utils.results import get_best_model_file\n",
    "from project_code.inference.parameters import get_core_parameter_predictions, convert_output_to_parameter_predictions, PARAMETER_COLS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a27ad0-d45c-4cd7-8f76-6b7e5cb96405",
   "metadata": {},
   "source": [
    "# Loading data and models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46ca4429-8308-4209-820d-cc5af232df98",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_folder = f'../data/processed/'\n",
    "\n",
    "dataset_of_model = {\n",
    "    'SRTaxo1NN': 'biologist_no_pub_age',  \n",
    "    'Taxo1NN': 'biologist_no_pub_age',  \n",
    "    'RandomForestRegressor': 'final_taxonomy_ecocodes',\n",
    "    'MultiTaskElasticNet': 'final_taxonomy_ecocodes',\n",
    "    'MLP': 'final_taxonomy_ecocodes',\n",
    "    'MLPSC': 'final_taxonomy_ecocodes',\n",
    "    'DEBNetHC': 'final_taxonomy_ecocodes',\n",
    "    'DEBNetSC': 'final_taxonomy_ecocodes',\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdfe15a-f2a3-4d6a-8bff-68d69219d767",
   "metadata": {},
   "source": [
    "## Loading best models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "453c4217-1395-4924-9c0c-efcac94e7a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_file, results_folder):\n",
    "    if model_file[-4:] == '.pkl':\n",
    "        with open(f\"{results_folder}/models/{model_file}\", 'rb') as f:\n",
    "            model = pickle.load(f)\n",
    "    elif model_file[-4:] == '.pth':\n",
    "        model = torch.load(f\"{results_folder}/models/{model_file}\", weights_only=False)\n",
    "        model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afab718e-51df-45a8-8571-1a905e6f1e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['SRTaxo1NN', 'MLP'])\n"
     ]
    }
   ],
   "source": [
    "best_models = {}\n",
    "best_models_test_performance_files = {}\n",
    "for mt in dataset_of_model.keys():  \n",
    "    results_folder = f'../results/{dataset_of_model[mt]}'\n",
    "    metric = 'logQ'\n",
    "    model_file = get_best_model_file(results_folder=results_folder, model_type=mt, metric=metric)\n",
    "    #print(mt, model_file)\n",
    "    if model_file is not None:\n",
    "        best_models[mt] = load_model(model_file, results_folder)\n",
    "        test_performance_filename =  model_file[:-4] + '.csv'\n",
    "        best_models_test_performance_files[mt] = os.path.join(results_folder, 'test_performance', test_performance_filename)\n",
    "\n",
    "print(best_models.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa112b35-2644-4156-9228-745ed0920349",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83ad6ad7-f6fb-442f-ae6a-f44ddb22bcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dfs = {}\n",
    "all_col_types = {}\n",
    "all_data = {}\n",
    "device = torch.device(\"cpu\")\n",
    "for dataset_name in list(set(dataset_of_model.values())):\n",
    "    results_folder = f'../results/{dataset_name}'\n",
    "    dfs, col_types = load_dataframes(dataset_name=dataset_name, data_split='train_test', datasets_folder=datasets_folder)\n",
    "    all_dfs[dataset_name] = dfs\n",
    "    all_col_types[dataset_name] = col_types \n",
    "    if 'biologist' in dataset_name:\n",
    "        if 'SRTaxo1NN' in best_models:\n",
    "            model = best_models['SRTaxo1NN']\n",
    "        elif 'Taxo1NN' in best_models:\n",
    "            model = best_models['Taxo1NN']\n",
    "        else:\n",
    "            continue\n",
    "        encoded_dfs = {}\n",
    "        # Encoded data with trained model encoders\n",
    "        for split in ('train', 'test'):\n",
    "            encoded_dfs[split] = model.regressor.encode_data(all_dfs[dataset_name][split])\n",
    "        all_data[dataset_name] = get_features_targets(data=encoded_dfs, col_types=all_col_types[dataset_name])\n",
    "    else:\n",
    "        data_tensors, dataloaders, datasets, scalers = prepare_data_tensors(data=dfs, col_types=col_types,\n",
    "                                                                            batch_size=1,\n",
    "                                                                            scaling_type='log_standardize',\n",
    "                                                                            device=device)\n",
    "        all_data[dataset_name] = data_tensors\n",
    "                                                                            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8dbe4d9-066c-46e4-8ba5-0569daec4f67",
   "metadata": {},
   "source": [
    "# Visualize predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4df1eae7-d917-48f2-af99-767ad14d8089",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxonomy_cols = [col for col in all_col_types['final_taxonomy_ecocodes']['input']['all'] if 'class' in col]\n",
    "\n",
    "hue_series = {\n",
    "    'metamorphosis': pd.concat([all_dfs['biologist_no_pub_age'][data_split]['metamorphosis'] for data_split in ['train', 'test']]),\n",
    "    'class': pd.concat([pd.from_dummies(all_dfs['final_taxonomy_ecocodes'][data_split][taxonomy_cols], sep='_') for data_split in ['train', 'test']])['class'],\n",
    "    'climate': None,\n",
    "    'habitat': None,\n",
    "    'migrate': None,\n",
    "    'food': None\n",
    "}\n",
    "\n",
    "hue_orders = {\n",
    "    'metamorphosis': [False, True],\n",
    "    'class': None,\n",
    "    'climate': None,\n",
    "    'habitat': None,\n",
    "    'migrate': None,\n",
    "    'food': None\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9b605ad-ce01-43bc-bed0-c5d3b9c15637",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca8083693c264671add92da8c6600070",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Model:', index=1, options=('SRTaxo1NN', 'MLP'), value='MLP'), Dropâ€¦"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def plot_residuals_df(model_type, plot_kind, data_split, groupby, scale):\n",
    "    # Get data for the model\n",
    "    dataset_name = dataset_of_model[model_type]\n",
    "    data = all_data[dataset_name]\n",
    "    col_types = all_col_types[dataset_name]\n",
    "    model = best_models[model_type]\n",
    "\n",
    "    # Get predictions:\n",
    "    X = data[data_split]['input']\n",
    "    y_true_ps = data[data_split]['output']\n",
    "    if 'DEBNet' in model_type:\n",
    "        y_pred_ps = model.predict(torch.tensor(X, dtype=torch.float32))\n",
    "    elif 'Taxo1NN' in model_type and data_split in ['train', 'val']:\n",
    "        distance_matrix = model.regressor_._compute_distance_matrix(model.regressor_.train_data, model.regressor_.train_data, data_split='train')\n",
    "        y_hat, indices = model.regressor_.get_predictions_from_distance_matrix(distance_matrix)\n",
    "        y_pred_ps = model.regressor_.apply_scaling_relationships(model.regressor_.train_data, y_hat, indices)\n",
    "    else:\n",
    "        y_pred_ps = model.predict(data[data_split]['input'])\n",
    "\n",
    "    if scale == 'model':\n",
    "        cols_to_plot = col_types['output']['all']\n",
    "        target_df = pd.DataFrame(y_true_ps, columns=col_types['output']['all'])\n",
    "        pred_df = pd.DataFrame(y_pred_ps, columns=col_types['output']['all'])\n",
    "        \n",
    "    elif scale == 'parameter':\n",
    "        cols_to_plot = PARAMETER_COLS     \n",
    "        mask = data[data_split]['mask']       \n",
    "        target_df = convert_output_to_parameter_predictions(y=y_true_ps, y_true=y_true_ps, mask=mask, col_types=col_types)\n",
    "        pred_df = convert_output_to_parameter_predictions(y=y_pred_ps, y_true=y_true_ps, mask=mask, col_types=col_types)\n",
    "\n",
    "    target_df.set_index(all_dfs[dataset_name][data_split].index, inplace=True)\n",
    "    pred_df.set_index(all_dfs[dataset_name][data_split].index, inplace=True)\n",
    "    if plot_kind == 'residual_vs_predicted':\n",
    "        if scale == 'model':\n",
    "            residuals_df = target_df - pred_df\n",
    "        elif scale == 'parameter':\n",
    "            residuals_df = (target_df - pred_df) / target_df  \n",
    "\n",
    "    # Plot predictions vs targets  \n",
    "    n_cols = 3\n",
    "    n_rows = np.ceil(len(cols_to_plot) / n_cols).astype(int)\n",
    "    fig, axes = plt.subplots(nrows=n_rows, ncols=n_cols, figsize=(16, 5*n_rows), tight_layout=True)\n",
    "    fig.suptitle(model_type, fontsize=16)\n",
    "    margin_factor = 0.05\n",
    "    for i, col in enumerate(cols_to_plot):\n",
    "        ax = axes[i // n_cols, i % n_cols]\n",
    "\n",
    "        if scale == 'parameter' and col != 'kap':\n",
    "            plot_log_scale_x = True\n",
    "            if plot_kind == 'residual_vs_predicted':\n",
    "                plot_log_scale_y = False\n",
    "            else:\n",
    "                plot_log_scale_y = True\n",
    "        elif scale == 'model' and (col in col_types['output']['log'] or 'Taxo1NN' in model_type):\n",
    "            plot_log_scale_x = True\n",
    "            plot_log_scale_y = True\n",
    "        else:\n",
    "            plot_log_scale_x = False\n",
    "            plot_log_scale_y = False\n",
    "        \n",
    "        if plot_kind == 'residual_vs_predicted':\n",
    "            sns.scatterplot(x=pred_df[col], y=residuals_df[col], ax=ax, hue=hue_series[groupby], hue_order=hue_orders[groupby]) # Fix\n",
    "            min_v = (1-margin_factor)*min(target_df[col].min(), pred_df[col].min())\n",
    "            max_v = (1+margin_factor)*max(target_df[col].max(), pred_df[col].max())\n",
    "            ax.set_xlim([min_v, max_v])\n",
    "\n",
    "            ax.plot([min_v, max_v], [0, 0], 'k--')\n",
    "            ax.set_ylabel('Residuals (actual - predicted)')\n",
    "\n",
    "        elif plot_kind == 'actual_vs_predicted':\n",
    "            sns.scatterplot(x=pred_df[col], y=target_df[col], ax=ax, hue=hue_series[groupby], hue_order=hue_orders[groupby])\n",
    "            min_v = (1-margin_factor)*min(target_df[col].min(), pred_df[col].min())\n",
    "            max_v = (1+margin_factor)*max(target_df[col].max(), pred_df[col].max())\n",
    "            ax.set_xlim([min_v, max_v])\n",
    "            ax.set_ylim([min_v, max_v])\n",
    "            ax.plot([min_v, max_v], [min_v, max_v], 'k--')\n",
    "            ax.set_ylabel('Actual values')\n",
    "\n",
    "        if plot_log_scale_x:\n",
    "            ax.set_xscale('log')\n",
    "        else:\n",
    "            ax.set_xscale('linear')\n",
    "        \n",
    "        if plot_log_scale_y:\n",
    "            ax.set_yscale('log')\n",
    "        else:\n",
    "            ax.set_yscale('linear')\n",
    "\n",
    "        ax.set_xlabel('Predicted values') \n",
    "        #r2 = metrics.r2_score(target_df, pred_df)\n",
    "        ax.set_title(f\"{col}\")\n",
    "\n",
    "model_selector = widgets.Dropdown(options=list(best_models.keys()), value='MLP', description='Model:')\n",
    "plot_selector = widgets.Dropdown(options=['actual_vs_predicted', 'residual_vs_predicted'], value='actual_vs_predicted', description='Plot Type:')\n",
    "data_split_selector = widgets.Dropdown(options=['train', 'test'], value='test', description='Data Split: ')\n",
    "groupby_selector = widgets.Dropdown(options=['metamorphosis', 'class', 'climate', 'habitat', 'migrate', 'food'])\n",
    "scale_selector = widgets.Dropdown(options=['model', 'parameter',], value='parameter')\n",
    "widgets.interactive(plot_residuals_df, model_type=model_selector, plot_kind=plot_selector, data_split=data_split_selector, groupby=groupby_selector, scale=scale_selector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3c2232-8d84-4003-94ff-f745c32ed215",
   "metadata": {},
   "source": [
    "# Save parameter predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2438c695-58b9-4d4e-8f78-b1bba3e1d030",
   "metadata": {},
   "source": [
    "### AmP values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b58f2cd6-a699-4dbb-97ab-8db1cf0bf426",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['z'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m col_types \u001b[38;5;241m=\u001b[39m all_col_types[dataset_name]\n\u001b[0;32m      4\u001b[0m gt_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat({ds: dfs[ds][col_types[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m'\u001b[39m]] \u001b[38;5;28;01mfor\u001b[39;00m ds \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m)})\u001b[38;5;241m.\u001b[39mreset_index(level\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, names\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata_split\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m gt_pars_df \u001b[38;5;241m=\u001b[39m \u001b[43mget_core_parameter_predictions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdfs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred_df\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgt_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m#gt_pars_df.to_csv(f'../results/parameter_predictions/AmP_predictions.csv', float_format='%.6e')\u001b[39;00m\n\u001b[0;32m      7\u001b[0m gt_pars_df\n",
      "File \u001b[1;32mc:\\Users\\diogo\\OneDrive - Universidade de Lisboa\\Terraprima\\Code\\DEB Model Calibration Algorithms\\DEB_ML_Bijection\\project_code\\inference\\parameters.py:172\u001b[0m, in \u001b[0;36mget_core_parameter_predictions\u001b[1;34m(dfs, pred_df)\u001b[0m\n\u001b[0;32m    169\u001b[0m     pars_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mE_Hj\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pars_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mE_Hj\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1e-10\u001b[39m)\n\u001b[0;32m    171\u001b[0m \u001b[38;5;66;03m# Convert to float\u001b[39;00m\n\u001b[1;32m--> 172\u001b[0m pars_df[AmP_CORE_DEB_PARS] \u001b[38;5;241m=\u001b[39m \u001b[43mpars_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43mAmP_CORE_DEB_PARS\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    174\u001b[0m \u001b[38;5;66;03m# Return only the predicitons for core parameters\u001b[39;00m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pars_df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata_split\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m AmP_CORE_DEB_PARS]\u001b[38;5;241m.\u001b[39mcopy()\n",
      "File \u001b[1;32mc:\\Users\\diogo\\miniconda3\\envs\\ml_bijection\\lib\\site-packages\\pandas\\core\\frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\diogo\\miniconda3\\envs\\ml_bijection\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\diogo\\miniconda3\\envs\\ml_bijection\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6251\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m-> 6252\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['z'] not in index\""
     ]
    }
   ],
   "source": [
    "dataset_name = 'biologist_no_pub_age'\n",
    "dfs = all_dfs[dataset_name]\n",
    "col_types = all_col_types[dataset_name]\n",
    "gt_df = pd.concat({ds: dfs[ds][col_types['output']['all']] for ds in ('train', 'test')}).reset_index(level=0, names='data_split')\n",
    "gt_pars_df = get_core_parameter_predictions(dfs, pred_df=gt_df)\n",
    "#gt_pars_df.to_csv(f'../results/parameter_predictions/AmP_predictions.csv', float_format='%.6e')\n",
    "gt_pars_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76dbea2-2e72-4b77-bc7c-ecde46bac9bb",
   "metadata": {},
   "source": [
    "### ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aeab3462-b367-4c6d-ac39-7be88b5b1278",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_parameter_predictions_old(model_type):\n",
    "    model = best_models[model_type]\n",
    "    dataset_name = dataset_of_model[model_type]\n",
    "    dfs = all_dfs[dataset_name]\n",
    "    data = all_data[dataset_name]\n",
    "    col_types = all_col_types[dataset_name]\n",
    "    pred_df = pd.DataFrame()\n",
    "    for split in ('train', 'test'):\n",
    "        if 'Taxo1NN' in model_type and split == 'train':\n",
    "            train_distance_matrix = model.regressor_._compute_distance_matrix(model.regressor_.train_data, model.regressor_.train_data, data_split='train')\n",
    "            y_hat, indices = model.regressor_.get_predictions_from_distance_matrix(train_distance_matrix)\n",
    "            y_pred = model.regressor_.apply_scaling_relationships(model.regressor_.train_data, y_hat, indices)\n",
    "        else:\n",
    "            y_pred = model.predict(data[split]['input'])\n",
    "        split_pred_df = pd.DataFrame(data=y_pred, index=dfs[split].index, columns=col_types['output']['all'])\n",
    "        split_pred_df['data_split'] = split\n",
    "        pred_df = pd.concat([pred_df, split_pred_df])\n",
    "    pars_df = get_core_parameter_predictions(dfs, pred_df=pred_df, col_types=col_types)\n",
    "    predictions_file_name = f'../results/parameter_predictions/{model_type}_predictions.csv'\n",
    "    pars_df.to_csv(predictions_file_name, float_format='%.10e')\n",
    "    print(f'Saved parameter predictions for model {model_type} in {predictions_file_name}')\n",
    "\n",
    "    return pars_df\n",
    "\n",
    "\n",
    "def save_parameter_predictions(model_type):\n",
    "    model = best_models[model_type]\n",
    "    dataset_name = dataset_of_model[model_type]\n",
    "    dfs = all_dfs[dataset_name]\n",
    "    data = all_data[dataset_name]\n",
    "    col_types = all_col_types[dataset_name]\n",
    "    pred_df = pd.DataFrame()\n",
    "    for split in ('train', 'test'):\n",
    "        if 'Taxo1NN' in model_type and split == 'train':\n",
    "            train_distance_matrix = model.regressor_._compute_distance_matrix(model.regressor_.train_data, model.regressor_.train_data, data_split='train')\n",
    "            y_hat, indices = model.regressor_.get_predictions_from_distance_matrix(train_distance_matrix)\n",
    "            y_pred = model.regressor_.apply_scaling_relationships(model.regressor_.train_data, y_hat, indices)\n",
    "        else:\n",
    "            y_pred = model.predict(data[split]['input'])\n",
    "        split_pred_df = convert_output_to_parameter_predictions(y=y_pred, y_true=data[split]['output'], mask=data[split]['mask'], col_types=col_types)\n",
    "        split_pred_df.set_index(dfs[split].index, inplace=True)\n",
    "        split_pred_df['data_split'] = split\n",
    "        pred_df = pd.concat([pred_df, split_pred_df])\n",
    "    pars_df = get_core_parameter_predictions(dfs, pred_df=pred_df)\n",
    "    predictions_file_name = f'../results/parameter_predictions/{model_type}_predictions.csv'\n",
    "    pars_df.to_csv(predictions_file_name, float_format='%.10e')\n",
    "    print(f'Saved parameter predictions for model {model_type} in {predictions_file_name}')\n",
    "\n",
    "    return pars_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e3a7de64-10a3-4f6c-8bd2-e809b69c9588",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved parameter predictions for model SRTaxo1NN in ../results/parameter_predictions/SRTaxo1NN_predictions.csv\n",
      "Saved parameter predictions for model MLP in ../results/parameter_predictions/MLP_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "for model_type in best_models:\n",
    "    save_parameter_predictions(model_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4677c590-1bb4-49c3-9366-f57800dfb1bb",
   "metadata": {},
   "source": [
    "# Compare parameter predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6136ab",
   "metadata": {},
   "source": [
    "## Test performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3eccbd-44ff-41d2-9c89-6a89311dbadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = best_models.keys()\n",
    "logQ_test_perf_df = pd.DataFrame(index=model_list, columns=PARAMETER_COLS)\n",
    "smape_test_perf_df = pd.DataFrame(index=model_list, columns=PARAMETER_COLS)\n",
    "for model_type in model_list:\n",
    "    model_test_df = pd.read_csv(f\"{best_models_test_performance_files[model_type]}\", index_col=0)\n",
    "    logQ_test_perf_df.loc[model_type, :] = model_test_df.loc[:, 'geometric_error_factor']\n",
    "    smape_test_perf_df.loc[model_type, :] = model_test_df.loc[:, 'symmetric_mean_absolute_percentage_error']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74582f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "logQ_test_perf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e67c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "smape_test_perf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089f5b04-0a2e-41bf-805c-5b3e53f159b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_labels = {\n",
    "    'DEBNetHC': 'DEBNet w/ HC',\n",
    "    'DEBNetSC': 'DEBNet w/ SC',\n",
    "    'Taxo1NN': 'Taxonomic 1-NN',\n",
    "    'SRTaxo1NN': 'Taxonomic 1-NN w/ S.R.',\n",
    "    'MultiTaskElasticNet': 'Elastic Net',\n",
    "    'RandomForestRegressor': 'Random Forest',\n",
    "    'MLP': 'MLP',\n",
    "    'MLPSC': 'MLP w/ SC',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0923af4f-704a-4e76-b6c2-28f8941c8844",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for mt, row in mape_df.iterrows():\n",
    "test_metrics_df_dict = {\n",
    "    'logQ': logQ_test_perf_df,\n",
    "    'sMAPE': smape_test_perf_df,\n",
    "}\n",
    "for metric, df in test_metrics_df_dict.items():\n",
    "    print(f'\\n\\n{metric} test performance:\\n')\n",
    "    for mt in model_list:\n",
    "        row = df.loc[mt]\n",
    "        line = f\"{model_labels[mt]} \"\n",
    "        for par in PARAMETER_COLS:\n",
    "            mape = row[par]\n",
    "            if mape == min(df[par]):\n",
    "                line += f' & \\\\textbf{{ {mape:.4f} }}'\n",
    "            else:\n",
    "                line += f' & {mape:.4f}'\n",
    "        line += ' \\\\\\\\'\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76872ab3-2e28-4571-a53f-dfc613449f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dfs['final_taxonomy_ecocodes']['test'].loc['Homo_sapiens']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_bijection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
