{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93f9e1c9-4fce-417b-a378-446dab13030b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import ipywidgets as widgets\n",
    "import pickle\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5874082-d253-47ca-9b6b-9c99a5fc76d9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the 'project' directory to the path\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "from project_code.data.load_data import load_dataframes\n",
    "from project_code.data.prepare_data_sklearn import get_features_targets\n",
    "from project_code.data.prepare_data_pytorch import prepare_data_tensors\n",
    "from project_code.utils.results import get_best_model_file\n",
    "from project_code.inference.parameters import get_core_parameter_predictions, convert_output_to_parameter_predictions, PARAMETER_COLS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a27ad0-d45c-4cd7-8f76-6b7e5cb96405",
   "metadata": {},
   "source": [
    "# Loading data and models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46ca4429-8308-4209-820d-cc5af232df98",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_folder = f'../data/processed/'\n",
    "\n",
    "dataset_of_model = {\n",
    "    'SRTaxo1NN': 'biologist_no_pub_age',  \n",
    "    'Taxo1NN': 'biologist_no_pub_age',  \n",
    "    'RandomForestRegressor': 'final_taxonomy_ecocodes',\n",
    "    'MultiTaskElasticNet': 'final_taxonomy_ecocodes',\n",
    "    'MLP': 'final_taxonomy_ecocodes',\n",
    "    'MLPSC': 'final_taxonomy_ecocodes',\n",
    "    'DEBNetHC': 'final_taxonomy_ecocodes',\n",
    "    'DEBNetSC': 'final_taxonomy_ecocodes',\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdfe15a-f2a3-4d6a-8bff-68d69219d767",
   "metadata": {},
   "source": [
    "## Loading best models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "453c4217-1395-4924-9c0c-efcac94e7a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_file, results_folder):\n",
    "    if model_file[-4:] == '.pkl':\n",
    "        with open(f\"{results_folder}/models/{model_file}\", 'rb') as f:\n",
    "            model = pickle.load(f)\n",
    "    elif model_file[-4:] == '.pth':\n",
    "        model = torch.load(f\"{results_folder}/models/{model_file}\", weights_only=False)\n",
    "        model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afab718e-51df-45a8-8571-1a905e6f1e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['SRTaxo1NN', 'Taxo1NN', 'MLP'])\n"
     ]
    }
   ],
   "source": [
    "best_models = {}\n",
    "best_models_test_performance_files = {}\n",
    "for mt in dataset_of_model.keys():  \n",
    "    results_folder = f'../results/{dataset_of_model[mt]}'\n",
    "    metric = 'logQ'\n",
    "    model_file = get_best_model_file(results_folder=results_folder, model_type=mt, metric=metric)\n",
    "    #print(mt, model_file)\n",
    "    if model_file is not None:\n",
    "        best_models[mt] = load_model(model_file, results_folder)\n",
    "        test_performance_filename =  model_file[:-4] + '.csv'\n",
    "        best_models_test_performance_files[mt] = os.path.join(results_folder, 'test_performance', test_performance_filename)\n",
    "\n",
    "print(best_models.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa112b35-2644-4156-9228-745ed0920349",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83ad6ad7-f6fb-442f-ae6a-f44ddb22bcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dfs = {}\n",
    "all_col_types = {}\n",
    "all_data = {}\n",
    "device = torch.device(\"cpu\")\n",
    "for dataset_name in list(set(dataset_of_model.values())):\n",
    "    results_folder = f'../results/{dataset_name}'\n",
    "    dfs, col_types = load_dataframes(dataset_name=dataset_name, data_split='train_test', datasets_folder=datasets_folder)\n",
    "    all_dfs[dataset_name] = dfs\n",
    "    all_col_types[dataset_name] = col_types \n",
    "    if 'biologist' in dataset_name:\n",
    "        if 'SRTaxo1NN' in best_models:\n",
    "            model = best_models['SRTaxo1NN']\n",
    "        elif 'Taxo1NN' in best_models:\n",
    "            model = best_models['Taxo1NN']\n",
    "        else:\n",
    "            continue\n",
    "        encoded_dfs = {}\n",
    "        # Encoded data with trained model encoders\n",
    "        for split in ('train', 'test'):\n",
    "            encoded_dfs[split] = model.regressor.encode_data(all_dfs[dataset_name][split])\n",
    "        all_data[dataset_name] = get_features_targets(data=encoded_dfs, col_types=all_col_types[dataset_name])\n",
    "    else:\n",
    "        data_tensors, dataloaders, datasets, scalers = prepare_data_tensors(data=dfs, col_types=col_types,\n",
    "                                                                            batch_size=1,\n",
    "                                                                            scaling_type='log_standardize',\n",
    "                                                                            device=device)\n",
    "        all_data[dataset_name] = data_tensors\n",
    "                                                                            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8dbe4d9-066c-46e4-8ba5-0569daec4f67",
   "metadata": {},
   "source": [
    "# Visualize predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4df1eae7-d917-48f2-af99-767ad14d8089",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxonomy_cols = [col for col in all_col_types['final_taxonomy_ecocodes']['input']['all'] if 'class' in col]\n",
    "\n",
    "hue_series = {\n",
    "    'metamorphosis': pd.concat([all_dfs['biologist_no_pub_age'][data_split]['metamorphosis'] for data_split in ['train', 'test']]),\n",
    "    'class': pd.concat([pd.from_dummies(all_dfs['final_taxonomy_ecocodes'][data_split][taxonomy_cols], sep='_') for data_split in ['train', 'test']])['class'],\n",
    "    'climate': None,\n",
    "    'habitat': None,\n",
    "    'migrate': None,\n",
    "    'food': None\n",
    "}\n",
    "\n",
    "hue_orders = {\n",
    "    'metamorphosis': [False, True],\n",
    "    'class': None,\n",
    "    'climate': None,\n",
    "    'habitat': None,\n",
    "    'migrate': None,\n",
    "    'food': None\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9b605ad-ce01-43bc-bed0-c5d3b9c15637",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65079745f9b041ba91a3688c82bdaa4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Model:', index=2, options=('SRTaxo1NN', 'Taxo1NN', 'MLP'), value='â€¦"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def plot_residuals_df(model_type, plot_kind, data_split, groupby, scale):\n",
    "    # Get data for the model\n",
    "    dataset_name = dataset_of_model[model_type]\n",
    "    data = all_data[dataset_name]\n",
    "    col_types = all_col_types[dataset_name]\n",
    "    model = best_models[model_type]\n",
    "\n",
    "    # Get predictions:\n",
    "    X = data[data_split]['input']\n",
    "    y_true_ps = data[data_split]['output']\n",
    "    if 'DEBNet' in model_type:\n",
    "        y_pred_ps = model.predict(torch.tensor(X, dtype=torch.float32))\n",
    "    elif 'Taxo1NN' in model_type and data_split in ['train', 'val']:\n",
    "        distance_matrix = model.regressor_._compute_distance_matrix(model.regressor_.train_data, model.regressor_.train_data, data_split='train')\n",
    "        y_hat, indices = model.regressor_.get_predictions_from_distance_matrix(distance_matrix)\n",
    "        y_pred_ps = model.regressor_.apply_scaling_relationships(model.regressor_.train_data, y_hat, indices)\n",
    "    else:\n",
    "        y_pred_ps = model.predict(data[data_split]['input'])\n",
    "\n",
    "    if scale == 'model':\n",
    "        cols_to_plot = col_types['output']['all']\n",
    "        target_df = pd.DataFrame(y_true_ps, columns=col_types['output']['all'])\n",
    "        pred_df = pd.DataFrame(y_pred_ps, columns=col_types['output']['all'])\n",
    "        \n",
    "    elif scale == 'parameter':\n",
    "        cols_to_plot = PARAMETER_COLS     \n",
    "        mask = data[data_split]['mask']       \n",
    "        target_df = convert_output_to_parameter_predictions(y=y_true_ps, y_true=y_true_ps, mask=mask, col_types=col_types)\n",
    "        pred_df = convert_output_to_parameter_predictions(y=y_pred_ps, y_true=y_true_ps, mask=mask, col_types=col_types)\n",
    "\n",
    "    target_df.set_index(all_dfs[dataset_name][data_split].index, inplace=True)\n",
    "    pred_df.set_index(all_dfs[dataset_name][data_split].index, inplace=True)\n",
    "    if plot_kind == 'residual_vs_predicted':\n",
    "        if scale == 'model':\n",
    "            residuals_df = target_df - pred_df\n",
    "        elif scale == 'parameter':\n",
    "            residuals_df = (target_df - pred_df) / target_df  \n",
    "\n",
    "    # Plot predictions vs targets  \n",
    "    n_cols = 3\n",
    "    n_rows = np.ceil(len(cols_to_plot) / n_cols).astype(int)\n",
    "    fig, axes = plt.subplots(nrows=n_rows, ncols=n_cols, figsize=(16, 5*n_rows), tight_layout=True)\n",
    "    fig.suptitle(model_type, fontsize=16)\n",
    "    margin_factor = 0.05\n",
    "    for i, col in enumerate(cols_to_plot):\n",
    "        ax = axes[i // n_cols, i % n_cols]\n",
    "\n",
    "        if scale == 'parameter' and col != 'kap':\n",
    "            plot_log_scale_x = True\n",
    "            if plot_kind == 'residual_vs_predicted':\n",
    "                plot_log_scale_y = False\n",
    "            else:\n",
    "                plot_log_scale_y = True\n",
    "        elif scale == 'model' and (col in col_types['output']['log'] or 'Taxo1NN' in model_type):\n",
    "            plot_log_scale_x = True\n",
    "            plot_log_scale_y = True\n",
    "        else:\n",
    "            plot_log_scale_x = False\n",
    "            plot_log_scale_y = False\n",
    "        \n",
    "        if plot_kind == 'residual_vs_predicted':\n",
    "            sns.scatterplot(x=pred_df[col], y=residuals_df[col], ax=ax, hue=hue_series[groupby], hue_order=hue_orders[groupby]) # Fix\n",
    "            min_v = (1-margin_factor)*min(target_df[col].min(), pred_df[col].min())\n",
    "            max_v = (1+margin_factor)*max(target_df[col].max(), pred_df[col].max())\n",
    "            ax.set_xlim([min_v, max_v])\n",
    "\n",
    "            ax.plot([min_v, max_v], [0, 0], 'k--')\n",
    "            ax.set_ylabel('Residuals (actual - predicted)')\n",
    "\n",
    "        elif plot_kind == 'actual_vs_predicted':\n",
    "            sns.scatterplot(x=pred_df[col], y=target_df[col], ax=ax, hue=hue_series[groupby], hue_order=hue_orders[groupby])\n",
    "            min_v = (1-margin_factor)*min(target_df[col].min(), pred_df[col].min())\n",
    "            max_v = (1+margin_factor)*max(target_df[col].max(), pred_df[col].max())\n",
    "            ax.set_xlim([min_v, max_v])\n",
    "            ax.set_ylim([min_v, max_v])\n",
    "            ax.plot([min_v, max_v], [min_v, max_v], 'k--')\n",
    "            ax.set_ylabel('Actual values')\n",
    "\n",
    "        if plot_log_scale_x:\n",
    "            ax.set_xscale('log')\n",
    "        else:\n",
    "            ax.set_xscale('linear')\n",
    "        \n",
    "        if plot_log_scale_y:\n",
    "            ax.set_yscale('log')\n",
    "        else:\n",
    "            ax.set_yscale('linear')\n",
    "\n",
    "        ax.set_xlabel('Predicted values') \n",
    "        #r2 = metrics.r2_score(target_df, pred_df)\n",
    "        ax.set_title(f\"{col}\")\n",
    "\n",
    "model_selector = widgets.Dropdown(options=list(best_models.keys()), value='MLP', description='Model:')\n",
    "plot_selector = widgets.Dropdown(options=['actual_vs_predicted', 'residual_vs_predicted'], value='actual_vs_predicted', description='Plot Type:')\n",
    "data_split_selector = widgets.Dropdown(options=['train', 'test'], value='test', description='Data Split: ')\n",
    "groupby_selector = widgets.Dropdown(options=['metamorphosis', 'class', 'climate', 'habitat', 'migrate', 'food'])\n",
    "scale_selector = widgets.Dropdown(options=['model', 'parameter',], value='parameter')\n",
    "widgets.interactive(plot_residuals_df, model_type=model_selector, plot_kind=plot_selector, data_split=data_split_selector, groupby=groupby_selector, scale=scale_selector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3c2232-8d84-4003-94ff-f745c32ed215",
   "metadata": {},
   "source": [
    "# Save parameter predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2438c695-58b9-4d4e-8f78-b1bba3e1d030",
   "metadata": {},
   "source": [
    "### AmP values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b58f2cd6-a699-4dbb-97ab-8db1cf0bf426",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'biologist_no_pub_age'\n",
    "dfs = all_dfs[dataset_name]\n",
    "col_types = all_col_types[dataset_name]\n",
    "#gt_df = pd.concat({ds: dfs[ds][col_types['output']['all']] for ds in ('train', 'test')}).reset_index(level=0, names='data_split')\n",
    "#gt_pars_df = get_core_parameter_predictions(dfs, pred_df=gt_df)\n",
    "#gt_pars_df.to_csv(f'../results/parameter_predictions/AmP_predictions.csv', float_format='%.6e')\n",
    "#gt_pars_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76dbea2-2e72-4b77-bc7c-ecde46bac9bb",
   "metadata": {},
   "source": [
    "### ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aeab3462-b367-4c6d-ac39-7be88b5b1278",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_parameter_predictions_old(model_type):\n",
    "    model = best_models[model_type]\n",
    "    dataset_name = dataset_of_model[model_type]\n",
    "    dfs = all_dfs[dataset_name]\n",
    "    data = all_data[dataset_name]\n",
    "    col_types = all_col_types[dataset_name]\n",
    "    pred_df = pd.DataFrame()\n",
    "    for split in ('train', 'test'):\n",
    "        if 'Taxo1NN' in model_type and split == 'train':\n",
    "            train_distance_matrix = model.regressor_._compute_distance_matrix(model.regressor_.train_data, model.regressor_.train_data, data_split='train')\n",
    "            y_hat, indices = model.regressor_.get_predictions_from_distance_matrix(train_distance_matrix)\n",
    "            y_pred = model.regressor_.apply_scaling_relationships(model.regressor_.train_data, y_hat, indices)\n",
    "        else:\n",
    "            y_pred = model.predict(data[split]['input'])\n",
    "        split_pred_df = pd.DataFrame(data=y_pred, index=dfs[split].index, columns=col_types['output']['all'])\n",
    "        split_pred_df['data_split'] = split\n",
    "        pred_df = pd.concat([pred_df, split_pred_df])\n",
    "    pars_df = get_core_parameter_predictions(dfs, pred_df=pred_df, col_types=col_types)\n",
    "    predictions_file_name = f'../results/parameter_predictions/{model_type}_predictions.csv'\n",
    "    pars_df.to_csv(predictions_file_name, float_format='%.10e')\n",
    "    print(f'Saved parameter predictions for model {model_type} in {predictions_file_name}')\n",
    "\n",
    "    return pars_df\n",
    "\n",
    "\n",
    "def save_parameter_predictions(model_type):\n",
    "    model = best_models[model_type]\n",
    "    dataset_name = dataset_of_model[model_type]\n",
    "    dfs = all_dfs[dataset_name]\n",
    "    data = all_data[dataset_name]\n",
    "    col_types = all_col_types[dataset_name]\n",
    "    pred_df = pd.DataFrame()\n",
    "    for split in ('train', 'test'):\n",
    "        if 'Taxo1NN' in model_type and split == 'train':\n",
    "            train_distance_matrix = model.regressor_._compute_distance_matrix(model.regressor_.train_data, model.regressor_.train_data, data_split='train')\n",
    "            y_hat, indices = model.regressor_.get_predictions_from_distance_matrix(train_distance_matrix)\n",
    "            y_pred = model.regressor_.apply_scaling_relationships(model.regressor_.train_data, y_hat, indices)\n",
    "        else:\n",
    "            y_pred = model.predict(data[split]['input'])\n",
    "        split_pred_df = convert_output_to_parameter_predictions(y=y_pred, y_true=data[split]['output'], mask=data[split]['mask'], col_types=col_types)\n",
    "        split_pred_df.set_index(dfs[split].index, inplace=True)\n",
    "        split_pred_df['data_split'] = split\n",
    "        pred_df = pd.concat([pred_df, split_pred_df])\n",
    "    pars_df = get_core_parameter_predictions(dfs, pred_df=pred_df)\n",
    "    predictions_file_name = f'../results/parameter_predictions/{model_type}_predictions.csv'\n",
    "    pars_df.to_csv(predictions_file_name, float_format='%.10e')\n",
    "    print(f'Saved parameter predictions for model {model_type} in {predictions_file_name}')\n",
    "\n",
    "    return pars_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3a7de64-10a3-4f6c-8bd2-e809b69c9588",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved parameter predictions for model SRTaxo1NN in ../results/parameter_predictions/SRTaxo1NN_predictions.csv\n",
      "Saved parameter predictions for model Taxo1NN in ../results/parameter_predictions/Taxo1NN_predictions.csv\n",
      "Saved parameter predictions for model MLP in ../results/parameter_predictions/MLP_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "for model_type in best_models:\n",
    "    save_parameter_predictions(model_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4677c590-1bb4-49c3-9366-f57800dfb1bb",
   "metadata": {},
   "source": [
    "# Compare parameter predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6136ab",
   "metadata": {},
   "source": [
    "## Test performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c3eccbd-44ff-41d2-9c89-6a89311dbadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = best_models.keys()\n",
    "logQ_test_perf_df = pd.DataFrame(index=model_list, columns=PARAMETER_COLS)\n",
    "smape_test_perf_df = pd.DataFrame(index=model_list, columns=PARAMETER_COLS)\n",
    "for model_type in model_list:\n",
    "    model_test_df = pd.read_csv(f\"{best_models_test_performance_files[model_type]}\", index_col=0)\n",
    "    logQ_test_perf_df.loc[model_type, :] = model_test_df.loc[:, 'log_accuracy_ratio']\n",
    "    smape_test_perf_df.loc[model_type, :] = model_test_df.loc[:, 'symmetric_mean_absolute_percentage_error']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74582f70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_Am</th>\n",
       "      <th>kap</th>\n",
       "      <th>v</th>\n",
       "      <th>p_M</th>\n",
       "      <th>E_Hb</th>\n",
       "      <th>E_Hj</th>\n",
       "      <th>E_Hp</th>\n",
       "      <th>k_J</th>\n",
       "      <th>s_M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SRTaxo1NN</th>\n",
       "      <td>1.091561</td>\n",
       "      <td>0.158283</td>\n",
       "      <td>0.496554</td>\n",
       "      <td>1.26274</td>\n",
       "      <td>1.655532</td>\n",
       "      <td>2.772625</td>\n",
       "      <td>1.385389</td>\n",
       "      <td>1.13844</td>\n",
       "      <td>0.588246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Taxo1NN</th>\n",
       "      <td>1.123633</td>\n",
       "      <td>0.155328</td>\n",
       "      <td>0.483032</td>\n",
       "      <td>1.214617</td>\n",
       "      <td>0.845133</td>\n",
       "      <td>2.841349</td>\n",
       "      <td>1.435638</td>\n",
       "      <td>1.121036</td>\n",
       "      <td>0.663127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP</th>\n",
       "      <td>0.672437</td>\n",
       "      <td>0.096931</td>\n",
       "      <td>0.37317</td>\n",
       "      <td>0.828903</td>\n",
       "      <td>0.974915</td>\n",
       "      <td>2.054981</td>\n",
       "      <td>0.877042</td>\n",
       "      <td>0.84983</td>\n",
       "      <td>0.53738</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               p_Am       kap         v       p_M      E_Hb      E_Hj  \\\n",
       "SRTaxo1NN  1.091561  0.158283  0.496554   1.26274  1.655532  2.772625   \n",
       "Taxo1NN    1.123633  0.155328  0.483032  1.214617  0.845133  2.841349   \n",
       "MLP        0.672437  0.096931   0.37317  0.828903  0.974915  2.054981   \n",
       "\n",
       "               E_Hp       k_J       s_M  \n",
       "SRTaxo1NN  1.385389   1.13844  0.588246  \n",
       "Taxo1NN    1.435638  1.121036  0.663127  \n",
       "MLP        0.877042   0.84983   0.53738  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logQ_test_perf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82e67c92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_Am</th>\n",
       "      <th>kap</th>\n",
       "      <th>v</th>\n",
       "      <th>p_M</th>\n",
       "      <th>E_Hb</th>\n",
       "      <th>E_Hj</th>\n",
       "      <th>E_Hp</th>\n",
       "      <th>k_J</th>\n",
       "      <th>s_M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SRTaxo1NN</th>\n",
       "      <td>39.071745</td>\n",
       "      <td>7.738836</td>\n",
       "      <td>21.814879</td>\n",
       "      <td>41.05639</td>\n",
       "      <td>49.595093</td>\n",
       "      <td>67.343778</td>\n",
       "      <td>48.05035</td>\n",
       "      <td>40.453595</td>\n",
       "      <td>26.620275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Taxo1NN</th>\n",
       "      <td>40.825543</td>\n",
       "      <td>7.590735</td>\n",
       "      <td>21.297077</td>\n",
       "      <td>40.701057</td>\n",
       "      <td>23.388019</td>\n",
       "      <td>67.631117</td>\n",
       "      <td>46.684678</td>\n",
       "      <td>39.873817</td>\n",
       "      <td>28.891509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP</th>\n",
       "      <td>28.702351</td>\n",
       "      <td>4.783999</td>\n",
       "      <td>17.25151</td>\n",
       "      <td>33.742659</td>\n",
       "      <td>39.039058</td>\n",
       "      <td>60.279702</td>\n",
       "      <td>36.119939</td>\n",
       "      <td>32.473531</td>\n",
       "      <td>24.814101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                p_Am       kap          v        p_M       E_Hb       E_Hj  \\\n",
       "SRTaxo1NN  39.071745  7.738836  21.814879   41.05639  49.595093  67.343778   \n",
       "Taxo1NN    40.825543  7.590735  21.297077  40.701057  23.388019  67.631117   \n",
       "MLP        28.702351  4.783999   17.25151  33.742659  39.039058  60.279702   \n",
       "\n",
       "                E_Hp        k_J        s_M  \n",
       "SRTaxo1NN   48.05035  40.453595  26.620275  \n",
       "Taxo1NN    46.684678  39.873817  28.891509  \n",
       "MLP        36.119939  32.473531  24.814101  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smape_test_perf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "089f5b04-0a2e-41bf-805c-5b3e53f159b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_labels = {\n",
    "    'DEBNetHC': 'DEBNet w/ HC',\n",
    "    'DEBNetSC': 'DEBNet w/ SC',\n",
    "    'Taxo1NN': 'Taxonomic 1-NN',\n",
    "    'SRTaxo1NN': 'Taxonomic 1-NN w/ S.R.',\n",
    "    'MultiTaskElasticNet': 'Elastic Net',\n",
    "    'RandomForestRegressor': 'Random Forest',\n",
    "    'MLP': 'MLP',\n",
    "    'MLPSC': 'MLP w/ SC',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0923af4f-704a-4e76-b6c2-28f8941c8844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "logQ test performance:\n",
      "\n",
      "Taxonomic 1-NN w/ S.R.  & 1.0916 & 0.1583 & 0.4966 & 1.2627 & 1.6555 & 2.7726 & 1.3854 & 1.1384 & 0.5882 \\\\\n",
      "Taxonomic 1-NN  & 1.1236 & 0.1553 & 0.4830 & 1.2146 & \\textbf{ 0.8451 } & 2.8413 & 1.4356 & 1.1210 & 0.6631 \\\\\n",
      "MLP  & \\textbf{ 0.6724 } & \\textbf{ 0.0969 } & \\textbf{ 0.3732 } & \\textbf{ 0.8289 } & 0.9749 & \\textbf{ 2.0550 } & \\textbf{ 0.8770 } & \\textbf{ 0.8498 } & \\textbf{ 0.5374 } \\\\\n",
      "\n",
      "\n",
      "sMAPE test performance:\n",
      "\n",
      "Taxonomic 1-NN w/ S.R.  & 39.0717 & 7.7388 & 21.8149 & 41.0564 & 49.5951 & 67.3438 & 48.0503 & 40.4536 & 26.6203 \\\\\n",
      "Taxonomic 1-NN  & 40.8255 & 7.5907 & 21.2971 & 40.7011 & \\textbf{ 23.3880 } & 67.6311 & 46.6847 & 39.8738 & 28.8915 \\\\\n",
      "MLP  & \\textbf{ 28.7024 } & \\textbf{ 4.7840 } & \\textbf{ 17.2515 } & \\textbf{ 33.7427 } & 39.0391 & \\textbf{ 60.2797 } & \\textbf{ 36.1199 } & \\textbf{ 32.4735 } & \\textbf{ 24.8141 } \\\\\n"
     ]
    }
   ],
   "source": [
    "#for mt, row in mape_df.iterrows():\n",
    "test_metrics_df_dict = {\n",
    "    'logQ': logQ_test_perf_df,\n",
    "    'sMAPE': smape_test_perf_df,\n",
    "}\n",
    "for metric, df in test_metrics_df_dict.items():\n",
    "    print(f'\\n\\n{metric} test performance:\\n')\n",
    "    for mt in model_list:\n",
    "        row = df.loc[mt]\n",
    "        line = f\"{model_labels[mt]} \"\n",
    "        for par in PARAMETER_COLS:\n",
    "            mape = row[par]\n",
    "            if mape == min(df[par]):\n",
    "                line += f' & \\\\textbf{{ {mape:.4f} }}'\n",
    "            else:\n",
    "                line += f' & {mape:.4f}'\n",
    "        line += ' \\\\\\\\'\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41ffbd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = 'Taxo1NN'\n",
    "model = best_models[model_type]\n",
    "dataset_name = dataset_of_model[model_type]\n",
    "dfs = all_dfs[dataset_name]\n",
    "data = all_data[dataset_name]\n",
    "col_types = all_col_types[dataset_name]\n",
    "pred_df = pd.DataFrame()\n",
    "for split in ('train', 'test'):\n",
    "    if 'Taxo1NN' in model_type and split == 'train':\n",
    "        train_distance_matrix = model.regressor_._compute_distance_matrix(model.regressor_.train_data, model.regressor_.train_data, data_split='train')\n",
    "        y_hat, indices = model.regressor_.get_predictions_from_distance_matrix(train_distance_matrix)\n",
    "        y_pred = model.regressor_.apply_scaling_relationships(model.regressor_.train_data, y_hat, indices)\n",
    "    else:\n",
    "        y_pred = model.predict(data[split]['input'])\n",
    "    split_pred_df = convert_output_to_parameter_predictions(y=y_pred, y_true=data[split]['output'], mask=data[split]['mask'], col_types=col_types)\n",
    "    split_pred_df.set_index(dfs[split].index, inplace=True)\n",
    "    split_pred_df['data_split'] = split\n",
    "    pred_df = pd.concat([pred_df, split_pred_df])\n",
    "pars_df = get_core_parameter_predictions(dfs, pred_df=pred_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ee00546",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data_split          train\n",
       "z                6.185801\n",
       "p_M            164.765016\n",
       "kap              0.567381\n",
       "v                0.025085\n",
       "E_G           5230.125523\n",
       "E_Hb             4.969683\n",
       "E_Hx             5.218168\n",
       "E_Hj             4.969683\n",
       "E_Hp          1358731.911\n",
       "k_J                 0.002\n",
       "Name: Amia_calva, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pars_df.loc['Amia_calva']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a86cc261",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "estim_kap                  True\n",
       "v                      0.025085\n",
       "family                  Amiidae\n",
       "estim_p_M                  True\n",
       "E_Hp                1358731.911\n",
       "E_Hj                   4.969683\n",
       "p_M                  164.765016\n",
       "Wwi                      3800.0\n",
       "d_V                         0.2\n",
       "k_J                       0.002\n",
       "estim_s_M                 False\n",
       "s_p_M                  0.091386\n",
       "E_Hb                   4.969683\n",
       "class            Actinopterygii\n",
       "estim_v                    True\n",
       "s_M                         1.0\n",
       "estim_s_p_M                True\n",
       "estim_E_Hb                 True\n",
       "order                Amiiformes\n",
       "metamorphosis             False\n",
       "estim_E_Hj                False\n",
       "estim_E_Hp                 True\n",
       "phylum                 Chordata\n",
       "kap                    0.567381\n",
       "estim_k_J                 False\n",
       "estim_p_Am                 True\n",
       "genus                      Amia\n",
       "Name: Amia_calva, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs['train'].loc['Amia_calva']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086643da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_bijection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
